{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Multiple Fibonacci Sequences with LLMapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When most people hear Map Reduce, they usually think Hadoop, Java, Big Data, etc. Map Reduce is actually a parallel programming model that has been around for a long time. It consists of two steps: a map step where an operation is executed on a number of files in parallel (like the throughput example we just talked about), and a reduce step where the output of the map step is combined into a single output.\n",
    "\n",
    "We have a file of multiple numbers we'd like to use as inputs to our Fibonacci code. We can use LLMapReduce to execute our code on each of these inputs. The map step calculates the first `n` values in the sequence and writes this to a text file. The reduce step combines those individual text files into a single file. We delete the intermediate files since they are no longer needed.\n",
    "\n",
    "Below shows an example of LLMapReduce for a word count problem. The map step is reading multiple files and calculating a word count on each, and the reduce step is merging the counts to get an overall count. Although the problem is different, the process is similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/MapReduce.png\" alt=\"Map Reduce\" style=\"height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapReduce with LLMapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By providing an input file, you can use LLMapReduce to run your executable on multiple inputs without having edit and recompile your code. All you need to do is write two short wrapper bash scripts.\n",
    "\n",
    "LLMapReduce is a command that is available on LLSC Systems and the MIT Supercloud. It is a bit like running a Job Array for the map step, followed by a serial job for the reduce step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Point: Submission Script for Serial Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, here is the starting submission (wrapper) script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "# Specify Input Number\n",
    "INPUTNUM=10\n",
    "\n",
    "echo \"Input number: \" $INPUTNUM\n",
    "\n",
    "# Run the executable\n",
    "../bin/fibonacci $INPUTNUM\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Map and Reduce Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to identify what we are doing as our map step and what the reduce step will be. The Map step can usually be identified by something you could do in an independent for loop. The Reduce step should take the result of the Map step and produce a single result. You may not always have a reduce step.\n",
    "\n",
    "Here we have a single operation (our fibonacci executable) that we want to map across many inputs. This is our map step. The map step will create a file for each input, so we can use a reduce step to combine these files into one single output file. This is easy enough to do on your own after the job runs, but it's a nice thing to automate.\n",
    "\n",
    "We'll start with our original submission script and renaming it `mapper.sh`. For now `reducer.sh` can be an empty bash script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit mapper.sh: Pass Arg1 to `fibonacci`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMapReduce will take the input file and split it up for you and call your script, passing in two inputs: one will be an input from your original file, the other will be a filename where you can write our the result of the map step.\n",
    "\n",
    "The original script defines an `$INPUTNUM` environment variable and passes that into our `fibonacci` executable. Instead we want to pass in the first argument that is passed into this script. This is in the environment variable `$1`. Note we are also printing the first argument to the log file, this can help with debugging.\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "# Print out args\n",
    "echo 'My arg 1: ' $1\n",
    "\n",
    "# Run the executable\n",
    "../bin/fibonacci $1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit mapper.sh: Write Result of `fibonacci` to Arg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want `mapper.sh` to write the output of the `fibonacci` code to the second argument, `$2`. Remember, this is the output file designated for this input. The `>` redirects the output of `../fibonacci $1` to the file `$2`. Again, we are printing out the second argument to help with any debugging or troubleshooting we may have to do.\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "# Print out args\n",
    "echo 'My arg 1: ' $1\n",
    "echo 'My arg 2: ' $2\n",
    "\n",
    "# Run the executable\n",
    "../bin/fibonacci $1 > $2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `mapper.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now might be a good time to make sure you are getting what you expect from the Map step. Go ahead and run:\n",
    "\n",
    "```bash\n",
    "LLMapReduce --mapper mapper.sh --input ../../../data/fibonacci/inputFile_10 --output fib_intermediate --np=4 --keep=true\n",
    "```\n",
    "\n",
    "For testing any parallel program, it's good to run on a smaller set of inputs, here we're using a file of 10 inputs. We're also using the `--keep=true` flag, which will keep the log files after the job is completed. These log files are deleted by default.\n",
    "\n",
    "Shortly after you run this, you should see two new directories. One called `fib_intermediate` and another with the prefix `MAPRED.`. The `fib_intermediate` directory should contain 10 files, one for each input in `inputFile_10`. Each file should have the expected output of one `fibonacci` run. If it doesn't you can check the log files in the `MAPRED.####/logs` directory for any errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `reducer.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `LLMapReduce` runs your `reducer.sh` script, it will again pass in two inputs:\n",
    "- `$1`: the directory where the map step wrote its results\n",
    "- `$2`: the name of a file to write any output of the reduce step\n",
    "\n",
    "In our `reducer.sh` script, we are first printing out these two arguments, like we did in the `mapper.sh` script. Then we are using the `cat` command to combine all the files in directory `$1`. Then we can use `>` again to redirect the output to the output file, `$2`. Finally, we can clean up after ourselves and remove the intermediate files. Feel free to comment out this last line the first few times you run or if you need to inspect the intermediate files for debugging purposes.\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "# Echo out the inputs\n",
    "echo 'My arg 1: ' $1\n",
    "echo 'My arg 2: ' $2\n",
    "\n",
    "# Combine all intermediate files into one output file\n",
    "cat $1/* > $2\n",
    "\n",
    "# Remove Intermediate Files\n",
    "rm -r $1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call LLMapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to call `LLMapReduce`:\n",
    "\n",
    "\n",
    "```bash\n",
    "LLMapReduce --mapper mapper.sh --reducer reducer.sh --input ../../../data/fibonacci/inputFile_10 --output fib_intermediate --np=4\n",
    "```\n",
    "\n",
    "After this runs you should see a file called `llmapreduce.out`. This will have the result of your reduce step. If you want it to have a different name, you can replace the `$2` in your reduce script with the name you want to give it.\n",
    "\n",
    "If you would like to keep the output and intermeidate files, say for debugging, you can add the option `--keep=true`. This will keep the log files that are written out.\n",
    "\n",
    "There are many options to `LLMapReduce`. You can see them with a short description by running `LLMapReduce -h` at the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mapper.sh`:\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "# Print out args\n",
    "echo 'My arg 1: ' $1\n",
    "echo 'My arg 2: ' $2\n",
    "\n",
    "# Run the executable\n",
    "../bin/fibonacci $1 > $2\n",
    "```\n",
    "\n",
    "`reducer.sh`:\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "# Echo out the inputs\n",
    "echo Arg 1 is :$1\n",
    "echo Arg 2 is :$2\n",
    "\n",
    "# Combine all intermediate files into one output file\n",
    "cat $1/* > $2\n",
    "\n",
    "# Remove Intermediate Files\n",
    "rm -r $1\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
