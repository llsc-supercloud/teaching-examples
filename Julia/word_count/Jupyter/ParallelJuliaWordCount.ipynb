{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Performance Computing Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go into some parallel programming with Julia, let's take a look at what a distributed High Performance Computing (HPC) system looks like.\n",
    "\n",
    "The intention for a HPC system is scale. Rather than scaling up for a single user by getting a better computer with more RAM, cores, etc (vertical scaling), an HPC system scales by combining a large number of machines that can be used by many users (horizontal scaling).\n",
    "\n",
    "Each machine in a distributed system is called a node. Most of the nodes are called \"compute nodes\", where the computational work gets done. There are few other nodes that have specialized tasks. The login node is where users log in to launch jobs. The scheduler node runs the scheduler, which is the software that allocates resources through which users launch jobs. The monitoring system keeps track of what is going on with the system. There is a shared file system that all compute nodes can see, so you don't have to worry about your data getting lost on some node's local file system, and a big switch that connects everything together. The LAN switch connects the system to the internet, so users can connect to it from their desktops and laptops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/MITSupercloud.png\" alt=\"Drawing\" style=\"height: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions and Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains a variable with a list of stopwords- words that will be removed and left out of the word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "countwords (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Statistics\n",
    "include(\"../word_count_helpers.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleantext function prepares text for word counting. It takes in the full text and removes punctuation, extra whitespace, and stopwords. Also converts all text to lowercase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```julia\n",
    "function cleantext(text)\n",
    "    \n",
    "    # Get full text without whitespace, punctuation, or stopwords\n",
    "    idx = findall(occursin.(\"***\",text))\n",
    "    text = text[idx[1]+1:idx[2]-1]\n",
    "    text = replace(join(text[text.!=\"\"],\" \"),r\"\\p{P}|[0-9]\" => \" \")\n",
    "    text = lowercase(replace(text, r\"\\s{2,}\" => \" \"))\n",
    "\n",
    "    for w in stopwords\n",
    "        text = replace(text,\" \"*w*\" \" => \" \");\n",
    "    end\n",
    "\n",
    "    return text\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The countwords function computes the number of times each word appears in the text. It takes in the cleaned text, and ouputs a dictionary of word counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```julia\n",
    "function countwords(text)\n",
    "    textSep = split(text,\" \")\n",
    "    wordcounts = Dict{String,Float64}()\n",
    "    for w in textSep\n",
    "        wordcounts[w] = get(wordcounts, w, 0) + 1\n",
    "    end\n",
    "    \n",
    "    return wordcounts\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Word Counts Serially"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before jumping straight into parallel implementations, it is important to first make sure you have working, efficent serial code. Code that does not run well in serial will not run well in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to calculate the word counts for each book, and output the top five for each book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair{String,Float64}[\"cavor\" => 302.0; \"moon\" => 212.0; \"time\" => 173.0; \"sphere\" => 127.0; \"earth\" => 119.0]\n",
      "Pair{String,Float64}[\"world\" => 233.0; \"men\" => 178.0; \"king\" => 177.0; \"man\" => 176.0; \"time\" => 131.0]\n",
      "Pair{String,Float64}[\"man\" => 214.0; \"montgomery\" => 205.0; \"moreau\" => 144.0; \"beast\" => 109.0; \"men\" => 101.0]\n",
      "Pair{String,Float64}[\"room\" => 35.0; \"candle\" => 21.0; \"door\" => 18.0; \"man\" => 17.0; \"hand\" => 13.0]\n",
      "Pair{String,Float64}[\"time\" => 201.0; \"machine\" => 86.0; \"man\" => 70.0; \"traveller\" => 61.0; \"white\" => 59.0]\n",
      "Pair{String,Float64}[\"martians\" => 164.0; \"people\" => 159.0; \"man\" => 126.0; \"time\" => 122.0; \"black\" => 122.0]\n",
      "Pair{String,Float64}[\"man\" => 260.0; \"kemp\" => 245.0; \"mr\" => 223.0; \"invisible\" => 181.0; \"door\" => 171.0]\n",
      "Pair{String,Float64}[\"veronica\" => 731.0; \"ann\" => 715.0; \"life\" => 208.0; \"man\" => 194.0; \"love\" => 188.0]\n",
      "Pair{String,Float64}[\"graham\" => 580.0; \"man\" => 355.0; \"people\" => 275.0; \"men\" => 207.0; \"ostrog\" => 187.0]\n",
      "Pair{String,Float64}[\"bert\" => 616.0; \"time\" => 228.0; \"air\" => 206.0; \"man\" => 181.0; \"men\" => 171.0]\n",
      "Pair{String,Float64}[\"redwood\" => 325.0; \"bensington\" => 210.0; \"cossar\" => 174.0; \"food\" => 174.0; \"great\" => 161.0]\n",
      "Pair{String,Float64}[\"red\" => 102.0; \"slim\" => 71.0; \"industrialist\" => 42.0; \"astronomer\" => 41.0; \"animals\" => 30.0]\n",
      "Pair{String,Float64}[\"mr\" => 881.0; \"polly\" => 762.0; \"man\" => 156.0; \"uncle\" => 152.0; \"time\" => 141.0]\n"
     ]
    }
   ],
   "source": [
    "# Load the file names\n",
    "dataLoc = \"../../../data/word_count/\";\n",
    "fnames = dataLoc.*readdir(dataLoc)\n",
    "\n",
    "# Iterate through file names\n",
    "for i = 1:length(fnames)\n",
    "\n",
    "    # Read in file and clean the text\n",
    "    text = readlines(fnames[i])\n",
    "    text = cleantext(text,stopwords)\n",
    "\n",
    "    # Count number of times each word appears\n",
    "    wordCounts = countwords(text)\n",
    "\n",
    "    # Sort and print the top 5 words with their counts\n",
    "    rankedwords = sort(collect(wordCounts), by=x->x[2], rev=true)\n",
    "    println(rankedwords[1:5,:])\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to find the top five overall word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair{String,Float64}[\"man\" => 1996.0; \"time\" => 1617.0; \"mr\" => 1527.0; \"people\" => 1128.0; \"world\" => 1119.0]\n"
     ]
    }
   ],
   "source": [
    "function getwordcounts(fname)\n",
    "    # Read in file and clean the text\n",
    "    f = open(fname)\n",
    "    text=cleantext(readlines(f))\n",
    "\n",
    "    # Count number of times each word appears\n",
    "    return countwords(text)\n",
    "end\n",
    "\n",
    "# Get counts for each book\n",
    "allcounts = getwordcounts.(fnames)\n",
    "\n",
    "# Calculate the overall word counts\n",
    "overallcounts = merge(+,allcounts...)\n",
    "\n",
    "# Sort and print the top 5 words with their counts\n",
    "println(sort(collect(overallcounts), by=x->x[2], rev=true)[1:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to get the top five words for each book, normalized by the overall count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair{String,Float64}[\"cavorite\" => 1.0; \"mooncalf\" => 1.0; \"lunar\" => 1.0; \"cavor\" => 1.0; \"selenites\" => 1.0]\n",
      "Pair{String,Float64}[\"leblanc\" => 1.0; \"holsten\" => 1.0; \"fowler\" => 1.0; \"brissago\" => 1.0; \"karenin\" => 1.0]\n",
      "Pair{String,Float64}[\"montgomery\" => 1.0; \"puma\" => 1.0; \"moreau\" => 1.0; \"prendick\" => 1.0; \"swine\" => 0.9642857142857143]\n",
      "Pair{String,Float64}[\"withered\" => 0.6923076923076923; \"candles\" => 0.6190476190476191; \"candle\" => 0.5675675675675675; \"shade\" => 0.2962962962962963; \"room\" => 0.06862745098039216]\n",
      "Pair{String,Float64}[\"psychologist\" => 1.0; \"morlocks\" => 1.0; \"weena\" => 1.0; \"filby\" => 1.0; \"sphinx\" => 1.0]\n",
      "Pair{String,Float64}[\"artilleryman\" => 1.0; \"ulla\" => 1.0; \"martian\" => 1.0; \"woking\" => 1.0; \"martians\" => 0.9939393939393939]\n",
      "Pair{String,Float64}[\"henfrey\" => 1.0; \"adye\" => 1.0; \"mariner\" => 1.0; \"griffin\" => 1.0; \"jaffers\" => 1.0]\n",
      "Pair{String,Float64}[\"vee\" => 1.0; \"ann\" => 1.0; \"alice\" => 1.0; \"miniver\" => 1.0; \"veronica\" => 1.0]\n",
      "Pair{String,Float64}[\"graham\" => 1.0; \"aeropile\" => 1.0; \"howard\" => 1.0; \"asano\" => 1.0; \"isbister\" => 1.0]\n",
      "Pair{String,Float64}[\"smallways\" => 1.0; \"edna\" => 1.0; \"germans\" => 1.0; \"bert\" => 1.0; \"butteridge\" => 1.0]\n",
      "Pair{String,Float64}[\"boomfood\" => 1.0; \"cossar\" => 1.0; \"hickleybrow\" => 1.0; \"wondershoot\" => 1.0; \"herakleophorbia\" => 1.0]\n",
      "Pair{String,Float64}[\"dad\" => 1.0; \"slim\" => 1.0; \"industrialist\" => 1.0; \"explorer\" => 0.9565217391304348; \"astronomer\" => 0.9534883720930233]\n",
      "Pair{String,Float64}[\"polly\" => 1.0; \"johnson\" => 1.0; \"rumbold\" => 1.0; \"fishbourne\" => 1.0; \"parsons\" => 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Get counts for each book\n",
    "allcounts = getwordcounts.(fnames)\n",
    "\n",
    "# Calculate the overall word counts\n",
    "overallcounts = merge(+,allcounts...)\n",
    "\n",
    "# Iterate through each set of word counts\n",
    "for counts in allcounts\n",
    "\n",
    "    # Calculate normalized score\n",
    "    thresh = quantile(collect(values(counts)), .98)\n",
    "    counts = filter!(word-> word.second > thresh, counts)\n",
    "    normscore = merge(/,counts,filter(word->haskey(counts,word.first), overallcounts))\n",
    "\n",
    "    # Sort and print the top 5 words with their normalized counts\n",
    "    rankedwords = sort(collect(normscore), by=x->x[2], rev=true)\n",
    "    println(rankedwords[1:min(5,length(counts)),:])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Throughput Parallel Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first and simplest parallel programming model is sometimes called \"Throughput\" or \"Pleasantly Parallel\" (you may have heard \"Embarassingly Parallel\" as well). It requires no communication between processes, and no aggregation of results. The biggest clue that you have something that can be considered Throughput is if you have a for loop, where no iteration depends on the one before it, and little or no work to do after it.\n",
    "\n",
    "In our first example, we are interating through a number of files, calculating something and outputing something for each file. Our other examples we have to do a bit more, they require some amount of communication between processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Throughput.png\" alt=\"Throughput\" style=\"height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia supports a Leader-Worker programming model, which is fairly intuitive for those new to paralell programming. There is a lead process, in this case the process attached to this Jupyter notebook, and several worker processes which you can add using the \"addprocs\" command. Since this notebook is running on a 16 core machine, I am adding 15 workers. If you are running this on your computer, you don't want to set this higher than the number of cores on your computer. You can see the number of workers by running the \"nworkers\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributed\n",
    "\n",
    "set_workers = 3\n",
    "\n",
    "if nworkers() < set_workers\n",
    "    addprocs(set_workers-(nprocs()-1))\n",
    "    \n",
    "end\n",
    "\n",
    "nworkers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of each worker process as a fresh Julia session that takes instruction from the leader process. Therefore, they each have their own memory space, so any variables or functions that have been defined on the leader process are not available on the worker processes. You can define a function on variable on all running processes by using the @everywhere macro.\n",
    "\n",
    "Why let each worker have access to the same memory space? This is fine if you are working on a single machine, however if you want to scale across several machines, this will not work. Julia enforces this scalability from the beginning.\n",
    "\n",
    "I've included the cleantext and countwords functions in the helpers.jl file so we can easily load them into all processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere begin\n",
    "    using DistributedArrays,Statistics\n",
    "    include(\"../Parallel/parallelhelpers.jl\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use Julia's Distributed Arrays package to do our parallel processing. This package works by creating arrays where each index of the array is assigned to a particular process. In this case, we are going to distribute the array of filenames. We can see which indices are assigned to which process by looking at the indices field of dfnames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Tuple{UnitRange{Int64}},1}:\n",
       " (1:5,)  \n",
       " (6:9,)  \n",
       " (10:13,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DistributedArrays\n",
    "\n",
    "dfnames = distribute(fnames)\n",
    "dfnames.indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the easiest ways to use distributed arrays, especially in a throughput context, is to use the broadcast operator. To do this, we need to define a function that executes a single iteration of the original for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function getcounts(fname)\n",
    "    \n",
    "    # Read in file and clean the text\n",
    "    text = readlines(fname)\n",
    "    text = cleantext(text,stopwords)\n",
    "    \n",
    "    # Count number of times each word appears\n",
    "    wordcounts = countwords(text)\n",
    "    \n",
    "    # Sort and print the top 5 words with their counts\n",
    "    rankedwords = sort(collect(wordcounts), by=x->x[2], rev=true)\n",
    "    println(rankedwords[1:5,:])\n",
    "    \n",
    "    return wordcounts\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can call getcounts on each element of the Distributed Array. The broadcast operator combined with the distributed array takes care of where each file gets processed, so you don't have to worry about that. The result is another distributed array with the result. (Run twice- the first time includes the compile time for the functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 3:\tPair{String,Float64}[\"martians\" => 164.0; \"people\" => 159.0; \"time\" => 122.0; \"black\" => 122.0; \"brother\" => 104.0]\n",
      "      From worker 2:\tPair{String,Float64}[\"cavor\" => 302.0; \"moon\" => 212.0; \"time\" => 173.0; \"sphere\" => 127.0; \"earth\" => 119.0]\n",
      "      From worker 4:\tPair{String,Float64}[\"bert\" => 616.0; \"time\" => 228.0; \"air\" => 206.0; \"great\" => 165.0; \"world\" => 155.0]\n",
      "      From worker 3:\tPair{String,Float64}[\"kemp\" => 245.0; \"mr\" => 223.0; \"invisible\" => 181.0; \"door\" => 171.0; \"hall\" => 160.0]\n",
      "      From worker 2:\tPair{String,Float64}[\"world\" => 233.0; \"king\" => 177.0; \"time\" => 131.0; \"great\" => 127.0; \"life\" => 101.0]\n",
      "      From worker 4:\tPair{String,Float64}[\"redwood\" => 325.0; \"bensington\" => 210.0; \"cossar\" => 174.0; \"food\" => 174.0; \"great\" => 161.0]\n",
      "      From worker 4:\tPair{String,Float64}[\"red\" => 102.0; \"slim\" => 71.0; \"industrialist\" => 42.0; \"astronomer\" => 41.0; \"animals\" => 30.0]\n",
      "      From worker 2:\tPair{String,Float64}[\"montgomery\" => 205.0; \"moreau\" => 144.0; \"beast\" => 109.0; \"face\" => 89.0; \"eyes\" => 88.0]\n",
      "      From worker 2:\tPair{String,Float64}[\"room\" => 35.0; \"candle\" => 21.0; \"door\" => 18.0; \"hand\" => 13.0; \"red\" => 13.0]\n",
      "      From worker 3:\tPair{String,Float64}[\"veronica\" => 731.0; \"ann\" => 715.0; \"life\" => 208.0; \"love\" => 188.0; \"time\" => 185.0]\n",
      "      From worker 2:\tPair{String,Float64}[\"time\" => 201.0; \"machine\" => 86.0; \"traveller\" => 61.0; \"white\" => 59.0; \"felt\" => 57.0]\n",
      "      From worker 4:\tPair{String,Float64}[\"mr\" => 881.0; \"polly\" => 762.0; \"uncle\" => 152.0; \"time\" => 141.0; \"johnson\" => 133.0]\n",
      "      From worker 3:\tPair{String,Float64}[\"graham\" => 580.0; \"people\" => 275.0; \"ostrog\" => 187.0; \"council\" => 153.0; \"great\" => 149.0]\n",
      "  4.158764 seconds (2.24 M allocations: 113.157 MiB, 0.81% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time allCounts = getcounts.(dfnames);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair{String,Float64}[\"cavor\" => 302.0; \"moon\" => 212.0; \"time\" => 173.0; \"sphere\" => 127.0; \"earth\" => 119.0]\n",
      "Pair{String,Float64}[\"world\" => 233.0; \"king\" => 177.0; \"time\" => 131.0; \"great\" => 127.0; \"life\" => 101.0]\n",
      "Pair{String,Float64}[\"montgomery\" => 205.0; \"moreau\" => 144.0; \"beast\" => 109.0; \"face\" => 89.0; \"eyes\" => 88.0]\n",
      "Pair{String,Float64}[\"room\" => 35.0; \"candle\" => 21.0; \"door\" => 18.0; \"hand\" => 13.0; \"red\" => 13.0]\n",
      "Pair{String,Float64}[\"time\" => 201.0; \"machine\" => 86.0; \"traveller\" => 61.0; \"white\" => 59.0; \"felt\" => 57.0]\n",
      "Pair{String,Float64}[\"martians\" => 164.0; \"people\" => 159.0; \"time\" => 122.0; \"black\" => 122.0; \"brother\" => 104.0]\n",
      "Pair{String,Float64}[\"kemp\" => 245.0; \"mr\" => 223.0; \"invisible\" => 181.0; \"door\" => 171.0; \"hall\" => 160.0]\n",
      "Pair{String,Float64}[\"veronica\" => 731.0; \"ann\" => 715.0; \"life\" => 208.0; \"love\" => 188.0; \"time\" => 185.0]\n",
      "Pair{String,Float64}[\"graham\" => 580.0; \"people\" => 275.0; \"ostrog\" => 187.0; \"council\" => 153.0; \"great\" => 149.0]\n",
      "Pair{String,Float64}[\"bert\" => 616.0; \"time\" => 228.0; \"air\" => 206.0; \"great\" => 165.0; \"world\" => 155.0]\n",
      "Pair{String,Float64}[\"redwood\" => 325.0; \"bensington\" => 210.0; \"cossar\" => 174.0; \"food\" => 174.0; \"great\" => 161.0]\n",
      "Pair{String,Float64}[\"red\" => 102.0; \"slim\" => 71.0; \"industrialist\" => 42.0; \"astronomer\" => 41.0; \"animals\" => 30.0]\n",
      "Pair{String,Float64}[\"mr\" => 881.0; \"polly\" => 762.0; \"uncle\" => 152.0; \"time\" => 141.0; \"johnson\" => 133.0]\n",
      "  3.550588 seconds (3.50 M allocations: 2.279 GiB, 4.00% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time getcounts.(fnames); # run this twice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When most people hear Map Reduce, they usually think Hadoop, Java, Big Data, etc. Map Reduce is actually a parallel programming model that has been around for a long time. It consists of two steps: a map step where an operation is executed on a number of files in paralell (like the throughput example we just talked about), and a reduce step where the output of the map step is combined into a single output.\n",
    "\n",
    "In our word count example, the top 5 overall word counts is a good example of a problem that fits the Map Reduce paradigm. Getting the individual word counts of each book is the Map step, and combining the individual word counts is the Reduce step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/MapReduce.png\" alt=\"Map Reduce\" style=\"height: 250px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Julia's Leader-Working model, this is pretty easy to do. The map step is done by the workers, the result is gathered on the local leader process, and the reduce step is done by the leader process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.438300 seconds (249.78 k allocations: 12.991 MiB)\n",
      "Pair{String,Float64}[\"time\" => 1617.0; \"mr\" => 1527.0; \"people\" => 1128.0; \"world\" => 1119.0; \"back\" => 989.0]\n"
     ]
    }
   ],
   "source": [
    "# Just redefining getcounts without the println statements\n",
    "@everywhere function getcounts_quiet(fname)\n",
    "    \n",
    "    # Read in file and clean the text\n",
    "    text = readlines(fname)\n",
    "    text = cleantext(text,stopwords)\n",
    "    \n",
    "    # Count number of times each word appears\n",
    "    wordcounts = countwords(text)\n",
    "    \n",
    "    return wordcounts\n",
    "end\n",
    "\n",
    "# This is the Map step\n",
    "@time allcounts = getcounts_quiet.(dfnames)\n",
    "allcounts_local = convert(Array,allcounts)\n",
    "\n",
    "# Reduce Step: Merge the counts from all files\n",
    "overallcounts = merge(+,allcounts_local...)\n",
    "\n",
    "# Sort and print the top 5 words with their counts\n",
    "println(sort(collect(overallcounts), by=x->x[2], rev=true)[1:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Complex Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of flexibility in how you can write a parallel program. It can be a bit overwhelming, but you start by identifying which steps can be done in parallel and where communication needs to happen. In the earlier examples this wasn't too hard, and you can move to a more complex problem by looking for the same patterns.\n",
    "\n",
    "There is no single right way to write a parallel program. It depends on the data and opeartions you are running. In this section, I'll go over three different ways to tackle the normalized word count problem. For fun, we'll time everything and make a nice plot at the end so we can see how much time is spent in each step and in communication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three steps to doing the normalized word count. We will need a function for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getcounts opens the the file passed in, cleans the text, and calls countwords\n",
    "@everywhere function getcounts(fname)\n",
    "    f = open(fname)\n",
    "    text = cleantext(readlines(f),stopwords)\n",
    "    return countwords(text)\n",
    "end\n",
    "\n",
    "# getglobalcount takes in an array of counts and merges them to get the overall count\n",
    "@everywhere function getoverallcount(counts)\n",
    "    return merge(+,counts...)\n",
    "end\n",
    "\n",
    "# getnormcount takes the a dictionary of counts, grabs the previously defined global count, and calculates the normalized count  \n",
    "@everywhere function getnormcount(counts,overallcounts)\n",
    "    # Calculate normalized score\n",
    "    thresh = quantile(collect(values(counts)), .98)\n",
    "    filteredcounts = filter!(word-> word.second > thresh, counts)\n",
    "    normscore = merge(/,counts,filter(word->haskey(filteredcounts,word.first), overallcounts))\n",
    "\n",
    "    # Sort and print the top 5 words with their normalized counts\n",
    "    rankedwords = sort(collect(normscore), by=x->x[2], rev=true)\n",
    "    println(rankedwords[1:min(5,length(rankedwords)),:])\n",
    "    return rankedwords\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually formulate normalized word count as a Map Reduce problem, where the reduce step also does the normalization on the leader process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/LooslyCoupled.png\" alt=\"Map Reduce\" style=\"height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair{String,Float64}[\"cavorite\" => 1.0; \"lunar\" => 1.0; \"selenites\" => 1.0; \"phi\" => 1.0; \"mooncalf\" => 1.0]\n",
      "Pair{String,Float64}[\"leblanc\" => 1.0; \"fowler\" => 1.0; \"brissago\" => 1.0; \"karenin\" => 1.0; \"holsten\" => 1.0]\n",
      "Pair{String,Float64}[\"montgomery\" => 1.0; \"prendick\" => 1.0; \"puma\" => 1.0; \"moreau\" => 1.0; \"swine\" => 0.9642857142857143]\n",
      "Pair{String,Float64}[\"withered\" => 0.6923076923076923; \"candles\" => 0.6190476190476191; \"candle\" => 0.5675675675675675; \"shade\" => 0.2962962962962963; \"room\" => 0.06862745098039216]\n",
      "Pair{String,Float64}[\"weena\" => 1.0; \"psychologist\" => 1.0; \"morlocks\" => 1.0; \"filby\" => 1.0; \"sphinx\" => 1.0]\n",
      "Pair{String,Float64}[\"martian\" => 1.0; \"artilleryman\" => 1.0; \"ulla\" => 1.0; \"woking\" => 1.0; \"martians\" => 0.9939393939393939]\n",
      "Pair{String,Float64}[\"henfrey\" => 1.0; \"adye\" => 1.0; \"mariner\" => 1.0; \"griffin\" => 1.0; \"jaffers\" => 1.0]\n",
      "Pair{String,Float64}[\"vee\" => 1.0; \"ann\" => 1.0; \"alice\" => 1.0; \"miniver\" => 1.0; \"veronica\" => 1.0]\n",
      "Pair{String,Float64}[\"aeropile\" => 1.0; \"graham\" => 1.0; \"howard\" => 1.0; \"asano\" => 1.0; \"isbister\" => 1.0]\n",
      "Pair{String,Float64}[\"smallways\" => 1.0; \"edna\" => 1.0; \"germans\" => 1.0; \"bert\" => 1.0; \"butteridge\" => 1.0]\n",
      "Pair{String,Float64}[\"hickleybrow\" => 1.0; \"wondershoot\" => 1.0; \"thir\" => 1.0; \"bensington\" => 1.0; \"winkles\" => 1.0]\n",
      "Pair{String,Float64}[\"dad\" => 1.0; \"slim\" => 1.0; \"industrialist\" => 1.0; \"explorer\" => 0.9565217391304348; \"astronomer\" => 0.9534883720930233]\n",
      "Pair{String,Float64}[\"polly\" => 1.0; \"johnson\" => 1.0; \"rumbold\" => 1.0; \"fishbourne\" => 1.0; \"parsons\" => 1.0]\n",
      "Pair{String,Float64}[\"cavor\" => 1.0; \"moon\" => 0.8153846153846154; \"time\" => 0.10698824984539271]\n",
      "Pair{String,Float64}[\"king\" => 0.885; \"world\" => 0.20822162645218945; \"great\" => 0.13612004287245444; \"time\" => 0.08101422387136673]\n",
      "Pair{String,Float64}[\"montgomery\" => 1.0; \"moreau\" => 1.0]\n",
      "Pair{String,Float64}[\"room\" => 0.06862745098039216]\n",
      "Pair{String,Float64}[\"machine\" => 0.2606060606060606; \"time\" => 0.12430426716141002]\n",
      "Pair{String,Float64}[\"martians\" => 0.9939393939393939; \"people\" => 0.14095744680851063]\n",
      "Pair{String,Float64}[\"kemp\" => 0.9919028340080972; \"invisible\" => 0.8080357142857143; \"mr\" => 0.14603798297314996]\n",
      "Pair{String,Float64}[\"ann\" => 1.0; \"veronica\" => 1.0; \"love\" => 0.6988847583643123; \"life\" => 0.2933709449929478]\n",
      "Pair{String,Float64}[\"graham\" => 1.0; \"ostrog\" => 1.0; \"council\" => 0.7463414634146341; \"people\" => 0.24379432624113476]\n",
      "Pair{String,Float64}[\"bert\" => 1.0; \"air\" => 0.31643625192012287; \"great\" => 0.17684887459807075; \"time\" => 0.14100185528756956]\n",
      "Pair{String,Float64}[\"bensington\" => 1.0; \"redwood\" => 1.0; \"cossar\" => 1.0; \"food\" => 0.5117647058823529]\n",
      "Pair{String,Float64}[\"red\" => 0.21888412017167383]\n",
      "Pair{String,Float64}[\"polly\" => 1.0; \"uncle\" => 0.9212121212121213; \"mr\" => 0.5769482645710543; \"time\" => 0.08719851576994433]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.288350153, 0.035092463, 0.009383253, 0.025129262)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the word counts\n",
    "# Broadcast over a distributed array automatically does the operation on the correct worker\n",
    "allcounts = getcounts.(dfnames)\n",
    "_,countTime1 = @timed begin\n",
    "    getcounts.(dfnames)\n",
    "end\n",
    "\n",
    "# Collect the distributed array onto the leader process\n",
    "allcountsL = convert(Array,allcounts)\n",
    "_,commTime1 = @timed convert(Array,allcounts)\n",
    "\n",
    "# Calculate the overall counts on the leader\n",
    "overallcounts = getoverallcount(allcountsL)\n",
    "_,aggTime1 = @timed getoverallcount(allcountsL)\n",
    "\n",
    "# Calculate the normalized counts on the leader and print results\n",
    "normcount = getnormcount.(allcountsL,Ref(overallcounts));\n",
    "_,normTime1 = @timed getnormcount.(allcountsL,Ref(overallcounts))\n",
    "\n",
    "countTime1,commTime1,aggTime1,normTime1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fork and Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way you can approach this problem is sometimes referred to as a Fork and Join paradigm. It's similar to the Map Reduce approach, however the final step is done in parallel, rather than on the leader process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ForkJoin.png\" alt=\"Fork and Join\" style=\"height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 3:\tPair{String,Float64}[\"artilleryman\" => 1.0; \"ulla\" => 1.0; \"martian\" => 1.0; \"woking\" => 1.0; \"martians\" => 0.9939393939393939]\n",
      "      From worker 3:\tPair{String,Float64}[\"henfrey\" => 1.0; \"adye\" => 1.0; \"mariner\" => 1.0; \"griffin\" => 1.0; \"jaffers\" => 1.0]\n",
      "      From worker 3:\tPair{String,Float64}[\"vee\" => 1.0; \"ann\" => 1.0; \"alice\" => 1.0; \"miniver\" => 1.0; \"veronica\" => 1.0]\n",
      "      From worker 2:\tPair{String,Float64}[\"cavorite\" => 1.0; \"mooncalf\" => 1.0; \"lunar\" => 1.0; \"cavor\" => 1.0; \"selenites\" => 1.0]\n",
      "      From worker 3:\tPair{String,Float64}[\"graham\" => 1.0; \"aeropile\" => 1.0; \"howard\" => 1.0; \"asano\" => 1.0; \"isbister\" => 1.0]\n",
      "      From worker 2:\tPair{String,Float64}[\"leblanc\" => 1.0; \"holsten\" => 1.0; \"fowler\" => 1.0; \"brissago\" => 1.0; \"karenin\" => 1.0]\n",
      "      From worker 2:\tPair{String,Float64}[\"montgomery\" => 1.0; \"puma\" => 1.0; \"moreau\" => 1.0; \"prendick\" => 1.0; \"swine\" => 0.9642857142857143]\n",
      "      From worker 2:\tPair{String,Float64}[\"withered\" => 0.6923076923076923; \"candles\" => 0.6190476190476191; \"candle\" => 0.5675675675675675; \"shade\" => 0.2962962962962963; \"room\" => 0.06862745098039216]\n",
      "      From worker 2:\tPair{String,Float64}[\"psychologist\" => 1.0; \"morlocks\" => 1.0; \"weena\" => 1.0; \"filby\" => 1.0; \"sphinx\" => 1.0]\n",
      "      From worker 4:\tPair{String,Float64}[\"smallways\" => 1.0; \"edna\" => 1.0; \"germans\" => 1.0; \"bert\" => 1.0; \"butteridge\" => 1.0]\n",
      "      From worker 4:\tPair{String,Float64}[\"boomfood\" => 1.0; \"cossar\" => 1.0; \"hickleybrow\" => 1.0; \"wondershoot\" => 1.0; \"herakleophorbia\" => 1.0]\n",
      "      From worker 4:\tPair{String,Float64}[\"dad\" => 1.0; \"slim\" => 1.0; \"industrialist\" => 1.0; \"explorer\" => 0.9565217391304348; \"astronomer\" => 0.9534883720930233]\n",
      "      From worker 4:\tPair{String,Float64}[\"polly\" => 1.0; \"johnson\" => 1.0; \"rumbold\" => 1.0; \"fishbourne\" => 1.0; \"parsons\" => 1.0]\n",
      "      From worker 2:\tPair{String,Float64}[\"cavor\" => 1.0; \"moon\" => 0.8153846153846154; \"time\" => 0.10698824984539271]\n",
      "      From worker 3:\tPair{String,Float64}[\"martians\" => 0.9939393939393939; \"people\" => 0.14095744680851063]\n",
      "      From worker 4:\tPair{String,Float64}[\"bert\" => 1.0; \"air\" => 0.31643625192012287; \"great\" => 0.17684887459807075; \"time\" => 0.14100185528756956]\n",
      "      From worker 2:\tPair{String,Float64}[\"king\" => 0.885; \"world\" => 0.20822162645218945; \"great\" => 0.13612004287245444; \"time\" => 0.08101422387136673]\n",
      "      From worker 3:\tPair{String,Float64}[\"kemp\" => 0.9919028340080972; \"invisible\" => 0.8080357142857143; \"mr\" => 0.14603798297314996]\n",
      "      From worker 4:\tPair{String,Float64}[\"cossar\" => 1.0; \"bensington\" => 1.0; \"redwood\" => 1.0; \"food\" => 0.5117647058823529]\n",
      "      From worker 2:\tPair{String,Float64}[\"montgomery\" => 1.0; \"moreau\" => 1.0]\n",
      "      From worker 3:\tPair{String,Float64}[\"ann\" => 1.0; \"veronica\" => 1.0; \"love\" => 0.6988847583643123; \"life\" => 0.2933709449929478]\n",
      "      From worker 4:\tPair{String,Float64}[\"red\" => 0.21888412017167383]\n",
      "      From worker 2:\tPair{String,Float64}[\"room\" => 0.06862745098039216]\n",
      "      From worker 3:\tPair{String,Float64}[\"graham\" => 1.0; \"ostrog\" => 1.0; \"council\" => 0.7463414634146341; \"people\" => 0.24379432624113476]\n",
      "      From worker 2:\tPair{String,Float64}[\"machine\" => 0.2606060606060606; \"time\" => 0.12430426716141002]\n",
      "      From worker 4:\tPair{String,Float64}[\"polly\" => 1.0; \"uncle\" => 0.9212121212121213; \"mr\" => 0.5769482645710543; \"time\" => 0.08719851576994433]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.279242312, 0.12091094699999999, 0.008811985, 0.021294513)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the word counts\n",
    "# Broadcast over a distributed array automatically does the operation on the correct worker\n",
    "allcountsD = getcounts.(dfnames)\n",
    "_,countTime2 = @timed getcounts.(dfnames)\n",
    "\n",
    "# Collect the distributed array onto the leader process\n",
    "allcountsL = convert(Array,allcountsD)\n",
    "_,commTime2 = @timed convert(Array,allcountsD)\n",
    "\n",
    "# Calculate the overall counts on leader process\n",
    "overallcounts = getoverallcount(allcountsL)\n",
    "_,aggTime2 = @timed getoverallcount(allcountsL)\n",
    "\n",
    "# Share the global counts with each of the workers\n",
    "_,t = @timed @eval @everywhere overallcounts=$overallcounts\n",
    "commTime2=commTime2+t\n",
    "\n",
    "# Calculate the normalized counts on each worker\n",
    "normcount = getnormcount.(allcountsD,Ref(overallcounts));\n",
    "_,normTime2 = @timed getnormcount.(allcountsD,Ref(overallcounts))\n",
    "\n",
    "countTime2,commTime2,aggTime2,normTime2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPMD: Single Program Multiple Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMPD is a very flexible parallel programming model that is fairly simple, but a little different than the way you might usually think about parallel programming. The idea is you have multiple processes, each with a process ID, and one program that they all run. The data that they run may be different depending on the process, and the processes usually communicate by sending and recieving messages.\n",
    "\n",
    "Notice in the figure below that each process is executing the same operations in the same order, but often on different data. Specifically, each process is doing the global count step locally. Often the cost of communication makes it worthwhile to the same operation on each process. Here there is a single all-to-all communication step, whereas the Fork and Join example had two (sending the local counts to the leader and sending the global counts to the workers).\n",
    "\n",
    "This is often the parallel programming model that is used for MPI, or Message Passing Interface, which is one of the most widely used parallel programming tools for high performance and scientific computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/SPMD.png\" alt=\"SPMD\" style=\"height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Julia's parallel programming model is Leader-Worker, this isn't true SPMD. However you can get the idea from this example. (Distributed Arrays does also have an SMPD mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 4:\tPair{String,Float64}[\"smallways\" => 1.0; \"edna\" => 1.0; \"germans\" => 1.0; \"bert\" => 1.0; \"butteridge\" => 1.0]\n",
      "      From worker 4:\tPair{String,Float64}[\"boomfood\" => 1.0; \"cossar\" => 1.0; \"hickleybrow\" => 1.0; \"wondershoot\" => 1.0; \"herakleophorbia\" => 1.0]\n",
      "      From worker 4:\tPair{String,Float64}[\"dad\" => 1.0; \"slim\" => 1.0; \"industrialist\" => 1.0; \"explorer\" => 0.9565217391304348; \"astronomer\" => 0.9534883720930233]\n",
      "      From worker 4:\tPair{String,Float64}[\"polly\" => 1.0; \"johnson\" => 1.0; \"rumbold\" => 1.0; \"fishbourne\" => 1.0; \"parsons\" => 1.0]\n",
      "      From worker 3:\tPair{String,Float64}[\"artilleryman\" => 1.0; \"ulla\" => 1.0; \"martian\" => 1.0; \"woking\" => 1.0; \"martians\" => 0.9939393939393939]\n",
      "      From worker 3:\tPair{String,Float64}[\"henfrey\" => 1.0; \"adye\" => 1.0; \"mariner\" => 1.0; \"griffin\" => 1.0; \"jaffers\" => 1.0]\n",
      "      From worker 2:\tPair{String,Float64}[\"cavorite\" => 1.0; \"mooncalf\" => 1.0; \"lunar\" => 1.0; \"cavor\" => 1.0; \"selenites\" => 1.0]\n",
      "      From worker 3:\tPair{String,Float64}[\"vee\" => 1.0; \"ann\" => 1.0; \"alice\" => 1.0; \"miniver\" => 1.0; \"veronica\" => 1.0]\n",
      "      From worker 2:\tPair{String,Float64}[\"leblanc\" => 1.0; \"holsten\" => 1.0; \"fowler\" => 1.0; \"brissago\" => 1.0; \"karenin\" => 1.0]\n",
      "      From worker 3:\tPair{String,Float64}[\"graham\" => 1.0; \"aeropile\" => 1.0; \"howard\" => 1.0; \"asano\" => 1.0; \"isbister\" => 1.0]\n",
      "      From worker 2:\tPair{String,Float64}[\"montgomery\" => 1.0; \"puma\" => 1.0; \"moreau\" => 1.0; \"prendick\" => 1.0; \"swine\" => 0.9642857142857143]\n",
      "      From worker 2:\tPair{String,Float64}[\"withered\" => 0.6923076923076923; \"candles\" => 0.6190476190476191; \"candle\" => 0.5675675675675675; \"shade\" => 0.2962962962962963; \"room\" => 0.06862745098039216]\n",
      "      From worker 2:\tPair{String,Float64}[\"psychologist\" => 1.0; \"morlocks\" => 1.0; \"weena\" => 1.0; \"filby\" => 1.0; \"sphinx\" => 1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.306100951, 0.158553747, 0.072432951, 0.03485715)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the word counts\n",
    "# Broadcast over a distributed array automatically does the operation on the correct worker\n",
    "_,countTime3 = @timed allcounts = getcounts.(dfnames)\n",
    "\n",
    "# Collect the distributed array onto the leader process and share with workers\n",
    "_,commTime3 = @timed begin\n",
    "    allcountsL = convert(Array,allcounts)\n",
    "    @eval @everywhere allcountsE = $allcountsL\n",
    "end\n",
    "\n",
    "# Calculate the overall counts on each woker\n",
    "_,aggTime3 = @timed @everywhere overallcounts = getoverallcount(allcountsE)\n",
    "\n",
    "# Calculate the normalized counts on each worker\n",
    "_,normTime3 = @timed getnormcount.(allcounts,Ref(overallcounts));\n",
    "\n",
    "countTime3,commTime3,aggTime3,normTime3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Parallel Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots,StatsPlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip3400\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip3400)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip3401\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip3400)\" d=\"\n",
       "M153.898 1487.47 L2352.76 1487.47 L2352.76 47.2441 L153.898 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip3402\">\n",
       "    <rect x=\"153\" y=\"47\" width=\"2200\" height=\"1441\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  470.537,1487.47 470.537,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1253.33,1487.47 1253.33,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2036.12,1487.47 2036.12,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  153.898,1446.71 2352.76,1446.71 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  153.898,1014.54 2352.76,1014.54 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  153.898,582.365 2352.76,582.365 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  153.898,150.191 2352.76,150.191 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  153.898,1487.47 2352.76,1487.47 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  153.898,1487.47 153.898,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  470.537,1487.47 470.537,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1253.33,1487.47 1253.33,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2036.12,1487.47 2036.12,1470.19 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  153.898,1446.71 180.284,1446.71 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  153.898,1014.54 180.284,1014.54 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  153.898,582.365 180.284,582.365 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  153.898,150.191 180.284,150.191 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 470.537, 1541.47)\" x=\"470.537\" y=\"1541.47\">Fork Join</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1253.33, 1541.47)\" x=\"1253.33\" y=\"1541.47\">Map Reduce</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 2036.12, 1541.47)\" x=\"2036.12\" y=\"1541.47\">SPMD</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 129.898, 1464.21)\" x=\"129.898\" y=\"1464.21\">0.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 129.898, 1032.04)\" x=\"129.898\" y=\"1032.04\">0.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 129.898, 599.865)\" x=\"129.898\" y=\"599.865\">1.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 129.898, 167.691)\" x=\"129.898\" y=\"167.691\">1.5</text>\n",
       "</g>\n",
       "<path clip-path=\"url(#clip3402)\" d=\"\n",
       "M274.839 1316.18 L274.839 210.471 L666.234 210.471 L666.234 1316.18 L274.839 1316.18 L274.839 1316.18  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  274.839,1316.18 274.839,210.471 666.234,210.471 666.234,1316.18 274.839,1316.18 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip3402)\" d=\"\n",
       "M1057.63 1386.55 L1057.63 272.967 L1449.02 272.967 L1449.02 1386.55 L1057.63 1386.55 L1057.63 1386.55  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1057.63,1386.55 1057.63,272.967 1449.02,272.967 1449.02,1386.55 1057.63,1386.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip3402)\" d=\"\n",
       "M1840.42 1216.93 L1840.42 88.0053 L2231.81 88.0053 L2231.81 1216.93 L1840.42 1216.93 L1840.42 1216.93  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1840.42,1216.93 1840.42,88.0053 2231.81,88.0053 2231.81,1216.93 1840.42,1216.93 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip3402)\" d=\"\n",
       "M274.839 1420.69 L274.839 1316.18 L666.234 1316.18 L666.234 1420.69 L274.839 1420.69 L274.839 1420.69  Z\n",
       "  \" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  274.839,1420.69 274.839,1316.18 666.234,1316.18 666.234,1420.69 274.839,1420.69 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip3402)\" d=\"\n",
       "M1057.63 1416.88 L1057.63 1386.55 L1449.02 1386.55 L1449.02 1416.88 L1057.63 1416.88 L1057.63 1416.88  Z\n",
       "  \" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1057.63,1416.88 1057.63,1386.55 1449.02,1386.55 1449.02,1416.88 1057.63,1416.88 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip3402)\" d=\"\n",
       "M1840.42 1353.98 L1840.42 1216.93 L2231.81 1216.93 L2231.81 1353.98 L1840.42 1353.98 L1840.42 1353.98  Z\n",
       "  \" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1840.42,1353.98 1840.42,1216.93 2231.81,1216.93 2231.81,1353.98 1840.42,1353.98 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip3402)\" d=\"\n",
       "M274.839 1428.31 L274.839 1420.69 L666.234 1420.69 L666.234 1428.31 L274.839 1428.31 L274.839 1428.31  Z\n",
       "  \" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  274.839,1428.31 274.839,1420.69 666.234,1420.69 666.234,1428.31 274.839,1428.31 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip3402)\" d=\"\n",
       "M1057.63 1424.99 L1057.63 1416.88 L1449.02 1416.88 L1449.02 1424.99 L1057.63 1424.99 L1057.63 1424.99  Z\n",
       "  \" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1057.63,1424.99 1057.63,1416.88 1449.02,1416.88 1449.02,1424.99 1057.63,1424.99 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip3402)\" d=\"\n",
       "M1840.42 1416.58 L1840.42 1353.98 L2231.81 1353.98 L2231.81 1416.58 L1840.42 1416.58 L1840.42 1416.58  Z\n",
       "  \" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1840.42,1416.58 1840.42,1353.98 2231.81,1353.98 2231.81,1416.58 1840.42,1416.58 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip3402)\" d=\"\n",
       "M274.839 1446.71 L274.839 1428.31 L666.234 1428.31 L666.234 1446.71 L274.839 1446.71 L274.839 1446.71  Z\n",
       "  \" fill=\"#c271d2\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  274.839,1446.71 274.839,1428.31 666.234,1428.31 666.234,1446.71 274.839,1446.71 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip3402)\" d=\"\n",
       "M1057.63 1446.71 L1057.63 1424.99 L1449.02 1424.99 L1449.02 1446.71 L1057.63 1446.71 L1057.63 1446.71  Z\n",
       "  \" fill=\"#c271d2\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1057.63,1446.71 1057.63,1424.99 1449.02,1424.99 1449.02,1446.71 1057.63,1446.71 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip3402)\" d=\"\n",
       "M1840.42 1446.71 L1840.42 1416.58 L2231.81 1416.58 L2231.81 1446.71 L1840.42 1446.71 L1840.42 1446.71  Z\n",
       "  \" fill=\"#c271d2\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3402)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1840.42,1446.71 1840.42,1416.58 2231.81,1416.58 2231.81,1446.71 1840.42,1446.71 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip3400)\" d=\"\n",
       "M1652.89 1343.47 L2280.76 1343.47 L2280.76 1041.07 L1652.89 1041.07  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1652.89,1343.47 2280.76,1343.47 2280.76,1041.07 1652.89,1041.07 1652.89,1343.47 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip3400)\" d=\"\n",
       "M1676.89 1125.75 L1820.89 1125.75 L1820.89 1077.36 L1676.89 1077.36 L1676.89 1125.75  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1676.89,1125.75 1820.89,1125.75 1820.89,1077.36 1676.89,1077.36 1676.89,1125.75 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 1844.89, 1119.05)\" x=\"1844.89\" y=\"1119.05\">1_Count</text>\n",
       "</g>\n",
       "<path clip-path=\"url(#clip3400)\" d=\"\n",
       "M1676.89 1186.23 L1820.89 1186.23 L1820.89 1137.84 L1676.89 1137.84 L1676.89 1186.23  Z\n",
       "  \" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1676.89,1186.23 1820.89,1186.23 1820.89,1137.84 1676.89,1137.84 1676.89,1186.23 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 1844.89, 1179.53)\" x=\"1844.89\" y=\"1179.53\">2_Communication</text>\n",
       "</g>\n",
       "<path clip-path=\"url(#clip3400)\" d=\"\n",
       "M1676.89 1246.71 L1820.89 1246.71 L1820.89 1198.32 L1676.89 1198.32 L1676.89 1246.71  Z\n",
       "  \" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1676.89,1246.71 1820.89,1246.71 1820.89,1198.32 1676.89,1198.32 1676.89,1246.71 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 1844.89, 1240.01)\" x=\"1844.89\" y=\"1240.01\">3_Merge</text>\n",
       "</g>\n",
       "<path clip-path=\"url(#clip3400)\" d=\"\n",
       "M1676.89 1307.19 L1820.89 1307.19 L1820.89 1258.8 L1676.89 1258.8 L1676.89 1307.19  Z\n",
       "  \" fill=\"#c271d2\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1676.89,1307.19 1820.89,1307.19 1820.89,1258.8 1676.89,1258.8 1676.89,1307.19 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3400)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 1844.89, 1300.49)\" x=\"1844.89\" y=\"1300.49\">4_Normalization</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timings = [countTime1 commTime1 aggTime1 normTime1; countTime2 commTime2 aggTime2 normTime2; countTime3 commTime3 aggTime3 normTime3]\n",
    "names = repeat([\"Map Reduce\"; \"Fork Join\"; \"SPMD\"],4)\n",
    "labels = repeat([\"1_Count\", \"2_Communication\", \"3_Merge\", \"4_Normalization\"], inner = 3)\n",
    "groupedbar(names, timings, group = labels, bar_position = :stack, bar_width=0.5, legend = :bottomright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
